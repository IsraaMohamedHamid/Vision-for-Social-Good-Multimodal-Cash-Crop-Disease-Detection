{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from vit_pytorch import ViT\n",
    "from torchvision.datasets.folder import is_image_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `crops` and directories (`train_dir`, `val_dir`, `test_dir`) are defined\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define main directories\n",
    "base_dir = '/Users/izzymohamed/Desktop/Vision For Social Good/Project/Vision-For-Social-Good/DATA' \n",
    "crop_root = os.path.join(base_dir, 'color') # color tester\n",
    "split_root = os.path.join(base_dir, 'split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV data\n",
    "csv_path = os.path.join(base_dir, 'plant_disease_multimodal_dataset.csv')  # '/Users/izzymohamed/Desktop/Vision For Social Good/Project/Vision-For-Social-Good/DATA/plant_disease_multimodal_dataset.csv'\n",
    "csv_data = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV data\n",
    "csv_data = pd.read_csv(csv_path)\n",
    "csv_image_paths = csv_data['Image Path'].values\n",
    "csv_labels = csv_data['Mapped Label'].values\n",
    "csv_features = csv_data.drop(columns=['Image Path', 'Mapped Label', 'Label']).values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "image_size = 224\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, csv_features, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.csv_features = csv_features\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        csv_feature = self.csv_features[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, csv_feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and dataloader\n",
    "dataset = CustomDataset(csv_image_paths, csv_features, csv_labels, transform=data_transforms)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "cnn_models = {\n",
    "    'InceptionV3': models.inception_v3(pretrained=True).to(device),\n",
    "    'ResNet152': models.resnet152(pretrained=True).to(device),\n",
    "    'VGG19': models.vgg19(pretrained=True).to(device),\n",
    "    'ViT': ViT(\n",
    "        image_size=image_size,\n",
    "        patch_size=16,\n",
    "        num_classes=1000,\n",
    "        dim=1024,\n",
    "        depth=6,\n",
    "        heads=16,\n",
    "        mlp_dim=2048,\n",
    "        dropout=0.1,\n",
    "        emb_dropout=0.1\n",
    "    ).to(device)\n",
    "}\n",
    "\n",
    "# Disable auxiliary logits for InceptionV3\n",
    "if 'InceptionV3' in cnn_models:\n",
    "    cnn_models['InceptionV3'].aux_logits = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features\n",
    "def extract_features(model, dataloader, device, feature_size, save_path):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    csv_features = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, csv_data, label) in enumerate(dataloader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            if isinstance(outputs, tuple):\n",
    "                outputs = outputs[0]\n",
    "            features.append(outputs.cpu().numpy())\n",
    "            csv_features.append(csv_data.numpy())\n",
    "            labels.append(label.numpy())\n",
    "\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    csv_features = np.concatenate(csv_features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "    np.save(os.path.join(save_path, f'{model.__class__.__name__}_features.npy'), features)\n",
    "    np.save(os.path.join(save_path, 'csv_features.npy'), csv_features)\n",
    "    np.save(os.path.join(save_path, 'labels.npy'), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and save features for each model\n",
    "feature_save_path = '/path/to/save_features'\n",
    "if not os.path.exists(feature_save_path):\n",
    "    os.makedirs(feature_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in cnn_models.items():\n",
    "    if model_name == 'ViT':\n",
    "        # Special handling for ViT if needed\n",
    "        pass\n",
    "    else:\n",
    "        feature_size = model.fc.in_features if hasattr(model, 'fc') else model.classifier[6].in_features\n",
    "        model.fc = nn.Identity() if hasattr(model, 'fc') else model.classifier[6] = nn.Identity()\n",
    "        extract_features(model, dataloader, device, feature_size, feature_save_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
