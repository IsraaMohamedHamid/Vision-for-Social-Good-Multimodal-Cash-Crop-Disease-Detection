{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from osgeo import gdal\n",
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to read images\n",
    "def read_image(file_path):\n",
    "    \"\"\"\n",
    "    Reads an image file. Determines if it's RGB or multispectral based on the file extension.\n",
    "    \"\"\"\n",
    "    if file_path.lower().endswith(('.tif', '.tiff')):\n",
    "        dataset = gdal.Open(file_path)\n",
    "        bands = [dataset.GetRasterBand(i).ReadAsArray() for i in range(1, dataset.RasterCount + 1)]\n",
    "        image = np.stack(bands, axis=-1)\n",
    "    else:\n",
    "        image = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Preprocesses an image (e.g., histogram equalization).\n",
    "    \"\"\"\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:  # RGB image\n",
    "        for i in range(3):\n",
    "            image[:, :, i] = exposure.equalize_hist(image[:, :, i])\n",
    "    else:  # Grayscale or single-band image\n",
    "        image = exposure.equalize_hist(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(directory):\n",
    "    \"\"\"\n",
    "    Processes all images in the given directory.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.tif', '.tiff')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                image = read_image(file_path)\n",
    "                processed_image = preprocess_image(image)\n",
    "                images.append(processed_image)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_images(images):\n",
    "    \"\"\"\n",
    "    Integrates multiple images into a single multimodal image.\n",
    "    \"\"\"\n",
    "    integrated_image = np.concatenate(images, axis=-1)\n",
    "    return integrated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to display images\n",
    "def get_image_statistics(image):\n",
    "    \"\"\"\n",
    "    Computes the mean and standard deviation of an image.\n",
    "    \"\"\"\n",
    "    if image is not None:\n",
    "        mean = np.mean(image, axis=(0, 1))\n",
    "        std = np.std(image, axis=(0, 1))\n",
    "        return mean, std\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizing the dataset\n",
    "def summarize_dataset(directory):\n",
    "    \"\"\"\n",
    "    Summarizes the dataset by computing the mean and standard deviation of each image.\n",
    "    \"\"\"\n",
    "    summary = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.tif', '.tiff')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                image = read_image(file_path)\n",
    "                mean, std = get_image_statistics(image)\n",
    "                summary.append({\n",
    "                    'file_path': file_path,\n",
    "                    'mean': mean,\n",
    "                    'std': std,\n",
    "                    'shape': image.shape if image is not None else None\n",
    "                })\n",
    "    return pd.DataFrame(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the dataset\n",
    "def visualize_summary(summary_df):\n",
    "    \"\"\"\n",
    "    Visualizes the summary of the dataset.\n",
    "    \"\"\"\n",
    "    # Mean and Standard Deviation Plots\n",
    "    means = np.stack(summary_df['mean'].dropna().values)\n",
    "    stds = np.stack(summary_df['std'].dropna().values)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(means, bins=30, alpha=0.7, label=['Band {}'.format(i+1) for i in range(means.shape[1])])\n",
    "    plt.title('Distribution of Mean Pixel Values')\n",
    "    plt.xlabel('Mean Pixel Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(stds, bins=30, alpha=0.7, label=['Band {}'.format(i+1) for i in range(stds.shape[1])])\n",
    "    plt.title('Distribution of Standard Deviation of Pixel Values')\n",
    "    plt.xlabel('Standard Deviation of Pixel Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the root path of the dataset\n",
    "dataset_root_path = '/Users/izzymohamed/Desktop/Vision For Social Good/DATA/Cherry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example directories (update paths based on your actual dataset structure)\n",
    "aerial_uav_path = os.path.join(dataset_root_path, '03_11_2021/Aerial_UAV_photos')\n",
    "ground_rgb_path = os.path.join(dataset_root_path, '03_11_2021/Ground_RGB_Photos')\n",
    "ground_multispectral_path = os.path.join(dataset_root_path, '03_11_2021/Ground_Multispectral_Photos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images from each modality\n",
    "aerial_uav_images = process_directory(aerial_uav_path)\n",
    "ground_rgb_images = process_directory(ground_rgb_path)\n",
    "ground_multispectral_images = process_directory(ground_multispectral_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate images from all modalities\n",
    "# all_images = aerial_uav_images + ground_rgb_images + ground_multispectral_images\n",
    "# integrated_image = integrate_images(all_images)\n",
    "\n",
    "# print(\"Integrated image shape:\", integrated_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize each dataset\n",
    "aerial_uav_summary = summarize_dataset(aerial_uav_path)\n",
    "ground_rgb_summary = summarize_dataset(ground_rgb_path)\n",
    "ground_multispectral_summary = summarize_dataset(ground_multispectral_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine summaries\n",
    "all_summary = pd.concat([aerial_uav_summary, ground_rgb_summary, ground_multispectral_summary], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary to CSV\n",
    "all_summary.to_csv('dataset_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Visualize summary\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvisualize_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_summary\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m, in \u001b[0;36mvisualize_summary\u001b[0;34m(summary_df)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mVisualizes the summary of the dataset.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Mean and Standard Deviation Plots\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m means \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m stds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(summary_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/core/shape_base.py:449\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    447\u001b[0m shapes \u001b[38;5;241m=\u001b[39m {arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall input arrays must have the same shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    451\u001b[0m result_ndim \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    452\u001b[0m axis \u001b[38;5;241m=\u001b[39m normalize_axis_index(axis, result_ndim)\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "# Visualize summary\n",
    "visualize_summary(all_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
