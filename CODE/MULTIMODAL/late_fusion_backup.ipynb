{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS, GPSTAGS\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets.folder import is_image_file\n",
    "\n",
    "from vit_pytorch import ViT\n",
    "\n",
    "from AACN_Model import attention_augmented_resnet152, attention_augmented_efficientnetb0, attention_augmented_inceptionv3, attention_augmented_vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define main directories\n",
    "base_dir = '/Users/izzymohamed/Desktop/Vision For Social Good/EXTRA/CODE/shubham10divakar Multimodal-Plant-Disease-Dataset/Data' \n",
    "crop_root = os.path.join(base_dir, 'color')\n",
    "split_root = os.path.join(base_dir, 'split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV data\n",
    "csv_path = '/Users/izzymohamed/Desktop/Vision For Social Good/EXTRA/CODE/shubham10divakar Multimodal-Plant-Disease-Dataset/Data/plant_disease_multimodal_dataset.csv'\n",
    "csv_data = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the image paths and labels from the features\n",
    "csv_image_paths = csv_data['Image Path'].values\n",
    "csv_labels = csv_data['Mapped Label'].values\n",
    "csv_features = csv_data.drop(columns=['Image Path', 'Mapped Label', 'Label']).values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to remove .DS_Store files\n",
    "def remove_ds_store(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == '.DS_Store' or '.DS_Store' in file:\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"Removing {file_path}\")\n",
    "                os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove .DS_Store files from base directory\n",
    "remove_ds_store(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a file is an image file\n",
    "def is_image_file(filename):\n",
    "    return filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split data into train, validation, and test sets\n",
    "def split_data(base_dir, val_split=0.4, test_split=0.1):\n",
    "    train_files = []\n",
    "    val_files = []\n",
    "    test_files = []\n",
    "\n",
    "    classes = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "    for cls in classes:\n",
    "        print(f'Processing class: {cls}')\n",
    "        class_dir = os.path.join(base_dir, cls)\n",
    "\n",
    "        images = [f for f in os.listdir(class_dir) if is_image_file(os.path.join(class_dir, f))]\n",
    "\n",
    "        if len(images) == 0:\n",
    "            print(f\"No images found for class {cls}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Shuffle images to randomize the selection\n",
    "        random.shuffle(images)\n",
    "\n",
    "        try:\n",
    "            train, test = train_test_split(images, test_size=test_split)\n",
    "            train, val = train_test_split(train, test_size=val_split / (1 - test_split))\n",
    "        except ValueError as e:\n",
    "            print(f\"Not enough images to split for class {cls}: {e}\")\n",
    "            continue\n",
    "\n",
    "        train_files.extend([(os.path.join(class_dir, img), cls) for img in train])\n",
    "        val_files.extend([(os.path.join(class_dir, img), cls) for img in val])\n",
    "        test_files.extend([(os.path.join(class_dir, img), cls) for img in test])\n",
    "\n",
    "    return train_files, val_files, test_files, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_files, val_files, test_files, classes = split_data(crop_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the lists of file paths for your dataset loading and transformations\n",
    "print(f\"Train files: {len(train_files)}\")\n",
    "print(f\"Validation files: {len(val_files)}\")\n",
    "print(f\"Test files: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the standard image sizes\n",
    "inception_size = 299\n",
    "other_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'InceptionV3': {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((inception_size, inception_size)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((inception_size, inception_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize((inception_size, inception_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    },\n",
    "    'Others': {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((other_size, other_size)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((other_size, other_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize((other_size, other_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMultimodalDataset(Dataset):\n",
    "    def __init__(self, file_paths, csv_features, csv_labels, class_to_idx, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.csv_features = csv_features\n",
    "        self.csv_labels = csv_labels\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, cls = self.file_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.class_to_idx[cls]\n",
    "        csv_row = self.csv_features[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, csv_row, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from class names to indices\n",
    "class_to_idx = {cls: idx for idx, cls in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and data loaders\n",
    "train_dataset_inception = CustomMultimodalDataset(train_files, csv_features, csv_labels, class_to_idx, transform=data_transforms['InceptionV3']['train'])\n",
    "val_dataset_inception = CustomMultimodalDataset(val_files, csv_features, csv_labels, class_to_idx, transform=data_transforms['InceptionV3']['val'])\n",
    "test_dataset_inception = CustomMultimodalDataset(test_files, csv_features, csv_labels, class_to_idx, transform=data_transforms['InceptionV3']['test'])\n",
    "\n",
    "train_loader_inception = DataLoader(train_dataset_inception, batch_size=32, shuffle=True)\n",
    "val_loader_inception = DataLoader(val_dataset_inception, batch_size=32, shuffle=True)\n",
    "test_loader_inception = DataLoader(test_dataset_inception, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaders for other models\n",
    "train_dataset_others = CustomMultimodalDataset(train_files, csv_features, csv_labels, class_to_idx, transform=data_transforms['Others']['train'])\n",
    "val_dataset_others = CustomMultimodalDataset(val_files, csv_features, csv_labels, class_to_idx, transform=data_transforms['Others']['val'])\n",
    "test_dataset_others = CustomMultimodalDataset(test_files, csv_features, csv_labels, class_to_idx, transform=data_transforms['Others']['test'])\n",
    "\n",
    "train_loader_others = DataLoader(train_dataset_others, batch_size=32, shuffle=True)\n",
    "val_loader_others = DataLoader(val_dataset_others, batch_size=32, shuffle=True)\n",
    "test_loader_others = DataLoader(test_dataset_others, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionAux(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(InceptionAux, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(in_channels, 128, kernel_size=1)\n",
    "        self.conv1 = nn.Conv2d(128, 768, kernel_size=3)  # Adjusted kernel size to 3\n",
    "        self.fc = nn.Linear(768, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        x = self.conv1(x)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.Inception3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionModel(nn.Module):\n",
    "    def __init__(self, base_model, csv_input_dim, num_classes, fusion_method='late'):\n",
    "        super(FusionModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.fusion_method = fusion_method\n",
    "\n",
    "        # Add support for the specific model\n",
    "        if isinstance(self.base_model, models.Inception3):\n",
    "            self.base_model.aux_logits = False\n",
    "            self.feature_size = 2048  # Output feature size for InceptionV3\n",
    "        elif isinstance(self.base_model, models.ResNet):\n",
    "            self.feature_size = self.base_model.fc.in_features  # Output feature size for ResNet\n",
    "            self.base_model.fc = nn.Identity()  # Replace the final fully connected layer with identity\n",
    "        elif isinstance(self.base_model, models.VGG):\n",
    "            self.feature_size = self.base_model.classifier[0].in_features  # Output feature size for VGG\n",
    "            self.base_model.classifier = nn.Identity()  # Replace the final classifier layer with identity\n",
    "        elif isinstance(self.base_model, ViT):\n",
    "            self.feature_size = self.base_model.dim  # Output feature size for ViT\n",
    "        elif isinstance(self.base_model, attention_augmented_resnet152) or isinstance(self.base_model, attention_augmented_inceptionv3):\n",
    "            self.feature_size = 2048  # Adjust as needed for attention-augmented models\n",
    "        else:\n",
    "            raise NotImplementedError(\"Model not supported\")\n",
    "\n",
    "        # Define CSV feature extractor\n",
    "        self.csv_fc = nn.Linear(csv_input_dim, 128)\n",
    "        \n",
    "        if fusion_method == 'intermediate':\n",
    "            self.fc1 = nn.Linear(128 + self.feature_size, 256)\n",
    "            self.fc2 = nn.Linear(256, num_classes)\n",
    "        elif fusion_method == 'late':\n",
    "            self.fc = nn.Linear(self.feature_size + 128, num_classes)\n",
    "    \n",
    "    def forward(self, x_img, x_csv):\n",
    "        # Extract features from image\n",
    "        x_img = self.base_model(x_img)\n",
    "\n",
    "        if isinstance(x_img, tuple):\n",
    "            x_img = x_img[0]\n",
    "        \n",
    "        # Extract features from CSV data\n",
    "        x_csv = F.relu(self.csv_fc(x_csv))\n",
    "        \n",
    "        if self.fusion_method == 'intermediate':\n",
    "            # Intermediate fusion\n",
    "            x = torch.cat((x_img, x_csv), dim=1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "        elif self.fusion_method == 'late':\n",
    "            # Late fusion\n",
    "            x = torch.cat((x_img, x_csv), dim=1)\n",
    "            x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and train the fusion model\n",
    "def create_and_train_fusion_model(model, train_loader, val_loader, num_classes, csv_input_dim, device, fusion_method='late', num_epochs=1, initial_lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr)\n",
    "    early_stopping_patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs_img, inputs_csv, labels = data\n",
    "            inputs_img, inputs_csv, labels = inputs_img.to(device), inputs_csv.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_img, inputs_csv)\n",
    "            if isinstance(outputs, tuple):\n",
    "                outputs = outputs[0]\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                inputs_img, inputs_csv, labels = data\n",
    "                inputs_img, inputs_csv, labels = inputs_img.to(device), inputs_csv.to(device), labels.to(device)\n",
    "                outputs = model(inputs_img, inputs_csv)\n",
    "                if isinstance(outputs, tuple):\n",
    "                    outputs = outputs[0]\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(\"Early stopping due to no improvement in validation loss.\")\n",
    "                break\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the fusion model\n",
    "def evaluate_fusion_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs_img, inputs_csv, labels = data\n",
    "            inputs_img, inputs_csv, labels = inputs_img.to(device), inputs_csv.to(device), labels.to(device)\n",
    "            outputs = model(inputs_img, inputs_csv)\n",
    "            if isinstance(outputs, tuple):\n",
    "                outputs = outputs[0]\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `crops` and directories (`train_dir`, `val_dir`, `test_dir`) are defined\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define crops and initialize results dictionary\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each crop\n",
    "train_dataset_inception = CustomMultimodalDataset(train_files, csv_features, csv_labels, class_to_idx, transform=data_transforms['InceptionV3']['train'])\n",
    "val_dataset_inception = CustomMultimodalDataset(val_files, csv_features, csv_labels, class_to_idx, transform=data_transforms['InceptionV3']['val'])\n",
    "test_dataset_inception = CustomMultimodalDataset(test_files, csv_features, csv_labels, class_to_idx, transform=data_transforms['InceptionV3']['test'])\n",
    "\n",
    "train_loader_inception = DataLoader(train_dataset_inception, batch_size=32, shuffle=True)\n",
    "val_loader_inception = DataLoader(val_dataset_inception, batch_size=32, shuffle=True)\n",
    "test_loader_inception = DataLoader(test_dataset_inception, batch_size=32, shuffle=False)\n",
    "\n",
    "train_dataset_others = CustomMultimodalDataset(train_files, csv_features, csv_labels, class_to_idx, transform=data_transforms['Others']['train'])\n",
    "val_dataset_others = CustomMultimodalDataset(val_files, csv_features, csv_labels, class_to_idx, transform=data_transforms['Others']['val'])\n",
    "test_dataset_others = CustomMultimodalDataset(test_files, csv_features, csv_labels, class_to_idx, transform=data_transforms['Others']['test'])\n",
    "\n",
    "train_loader_others = DataLoader(train_dataset_others, batch_size=32, shuffle=True)\n",
    "val_loader_others = DataLoader(val_dataset_others, batch_size=32, shuffle=True)\n",
    "test_loader_others = DataLoader(test_dataset_others, batch_size=32, shuffle=False)\n",
    "\n",
    "num_classes_inception = len(class_to_idx)\n",
    "num_classes_others = len(class_to_idx)\n",
    "\n",
    "num_heads = 8\n",
    "csv_input_dim = csv_features.shape[1]\n",
    "\n",
    "pretrained_models = {\n",
    "    # 'InceptionV3': models.inception_v3(pretrained=True, aux_logits=True),\n",
    "    # 'ResNet152': models.resnet152(pretrained=True),\n",
    "    # 'VGG19': models.vgg19(pretrained=True),\n",
    "    \"AttentionAugmentedResNet152\": attention_augmented_resnet152(num_classes=num_classes_others, attention=[False, True, True, True], num_heads=num_heads),\n",
    "    \"AttentionAugmentedInceptionV3\": attention_augmented_inceptionv3(attention=True),\n",
    "    'ViT': ViT(\n",
    "        image_size=224,\n",
    "        patch_size=16,\n",
    "        num_classes=num_classes_others,\n",
    "        dim=1024,\n",
    "        depth=6,\n",
    "        heads=16,\n",
    "        mlp_dim=2048,\n",
    "        dropout=0.1,\n",
    "        emb_dropout=0.1\n",
    "    ),\n",
    "}\n",
    "\n",
    "if 'InceptionV3' in pretrained_models:\n",
    "    pretrained_models['InceptionV3'].aux_logits = False\n",
    "\n",
    "crop_results = {}\n",
    "\n",
    "for model_name, base_model in pretrained_models.items():\n",
    "    for fusion_method in ['late', 'intermediate']:\n",
    "        fusion_model = FusionModel(base_model, csv_input_dim, num_classes_others, fusion_method)\n",
    "\n",
    "        print(f'Training {model_name} with {fusion_method} fusion')\n",
    "        model = create_and_train_fusion_model(fusion_model, train_loader_others, val_loader_others, num_classes_others, csv_input_dim, device, fusion_method, initial_lr=0.001)\n",
    "\n",
    "        test_loss, test_accuracy = evaluate_fusion_model(model, test_loader_others, nn.CrossEntropyLoss(), device)\n",
    "\n",
    "        crop_results[f\"{model_name}_{fusion_method}\"] = {\n",
    "            'model': model,\n",
    "            'test_loss': test_loss,\n",
    "            'test_accuracy': test_accuracy\n",
    "        }\n",
    "        print(f'{crop} - {model_name} with {fusion_method} fusion Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "results[crop] = crop_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and data loaders\n",
    "train_dataset_inception = CustomMultimodalDataset(train_files, csv_features, csv_labels, class_to_idx, transform=data_transforms['InceptionV3']['train'])\n",
    "val_dataset_inception = CustomMultimodalDataset(val_files, csv_features, csv_labels, class_to_idx, transform=data_transforms['InceptionV3']['val'])\n",
    "test_dataset_inception = CustomMultimodalDataset(test_files, csv_features, csv_labels, class_to_idx, transform=data_transforms['InceptionV3']['test'])\n",
    "\n",
    "train_loader_inception = DataLoader(train_dataset_inception, batch_size=32, shuffle=True)\n",
    "val_loader_inception = DataLoader(val_dataset_inception, batch_size=32, shuffle=True)\n",
    "test_loader_inception = DataLoader(test_dataset_inception, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display F1, precision, and recall of all models as a table\n",
    "def display_model_metrics_table(results, test_loader):\n",
    "    metrics_data = []\n",
    "    \n",
    "    for crop, crop_results in results.items():\n",
    "        for model_name, model_info in crop_results.items():\n",
    "            model = model_info['model']\n",
    "            device = next(model.parameters()).device  # Get the device of the model\n",
    "            model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "            all_labels = []\n",
    "            all_predicted = []\n",
    "\n",
    "            for images, csv_data, labels in test_loader:\n",
    "                images, csv_data, labels = images.to(device), csv_data.to(device), labels.to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(images, csv_data)\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_predicted.extend(predicted.cpu().numpy())\n",
    "\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predicted, average='macro')           \n",
    "            metrics_data.append({\n",
    "                'Crop': crop,\n",
    "                'Model': model_name,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'F1-score': f1\n",
    "            })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    display(metrics_df)  # Display the DataFrame in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display the classification report of a given model\n",
    "def display_classification_report(model, test_loader):\n",
    "    device = next(model.parameters()).device  # Get the device of the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    all_labels = []\n",
    "    all_predicted = []\n",
    "\n",
    "    for images, csv_data, labels in test_loader:\n",
    "        images, csv_data, labels = images.to(device), csv_data.to(device), labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images, csv_data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predicted.extend(predicted.cpu().numpy())\n",
    "\n",
    "    report = classification_report(all_labels, all_predicted, target_names=test_loader.dataset.class_to_idx.keys())\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some correctly and incorrectly classified images\n",
    "def display_classification_results(model, test_loader, num_images=5):\n",
    "    device = next(model.parameters()).device  # Get the device of the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    class_labels = list(test_loader.dataset.class_to_idx.keys())\n",
    "    \n",
    "    images, csv_data, labels = next(iter(test_loader))\n",
    "    images, csv_data, labels = images[:num_images].to(device), csv_data[:num_images].to(device), labels[:num_images].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images, csv_data)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(20, 8))\n",
    "    fig.suptitle('Classification Results', fontsize=16)\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        ax = axes[i]\n",
    "        img = images[i].cpu().numpy().transpose((1, 2, 0))\n",
    "        img = np.clip(img, 0, 1)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f'True: {class_labels[labels[i]]}\\n Pred: {class_labels[predicted[i].cpu()]}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the table of metrics for all models\n",
    "display_model_metrics_table(results, test_loader_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results for each crop\n",
    "for crop, crop_results in results.items():\n",
    "    for model_name in crop_results.keys():\n",
    "        print(f'Displaying results for {crop} - {model_name}')\n",
    "        display_classification_results(crop_results[model_name]['model'], test_loader_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results for each crop\n",
    "for crop, crop_results in results.items():\n",
    "    for model_name in crop_results.keys():\n",
    "        print(f'Displaying classification report for {crop} - {model_name}')\n",
    "        display_classification_report(crop_results[model_name]['model'], test_loader_others)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
