{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import os\n","import shutil\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from IPython.display import display\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import precision_recall_fscore_support, classification_report\n","\n","from PIL import Image\n","from PIL.ExifTags import TAGS, GPSTAGS\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers, models, optimizers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import InceptionV3, ResNet152, VGG19\n","from tensorflow.keras.utils import to_categorical, Sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# List all physical GPUs available\n","physical_devices = tf.config.list_physical_devices('GPU')\n","print(\"Num GPUs Available: \", len(physical_devices))\n","\n","# Print details about the detected GPUs\n","for gpu in physical_devices:\n","    print(\"GPU details:\", gpu)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Enable device placement logging\n","tf.debugging.set_log_device_placement(True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["base_dir = '/kaggle/input/multimodal-plant-disease-dataset-by-subham-divakar'\n","crop_root = os.path.join(base_dir, 'color')\n","split_root = os.path.join(base_dir, 'split')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def remove_ds_store(directory):\n","    for root, dirs, files in os.walk(directory):\n","        for file in files:\n","            if file == '.DS_Store' or '.DS_Store' in file:\n","                file_path = os.path.join(root, file)\n","                print(f\"Removing {file_path}\")\n","                os.remove(file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["remove_ds_store(base_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def is_image_file(filename):\n","    return filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif'))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def split_data(base_dir, val_split=0.4, test_split=0.1):\n","    train_files = []\n","    val_files = []\n","    test_files = []\n","\n","    classes = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n","    for cls in classes:\n","        print(f'Processing class: {cls}')\n","        class_dir = os.path.join(base_dir, cls)\n","\n","        images = [f for f in os.listdir(class_dir) if is_image_file(os.path.join(class_dir, f))]\n","\n","        if len(images) == 0:\n","            print(f\"No images found for class {cls}. Skipping...\")\n","            continue\n","\n","        random.shuffle(images)\n","\n","        try:\n","            train, test = train_test_split(images, test_size=test_split)\n","            train, val = train_test_split(train, test_size=val_split / (1 - test_split))\n","        except ValueError as e:\n","            print(f\"Not enough images to split for class {cls}: {e}\")\n","            continue\n","\n","        train_files.extend([(os.path.join(class_dir, img), cls) for img in train])\n","        val_files.extend([(os.path.join(class_dir, img), cls) for img in val])\n","        test_files.extend([(os.path.join(class_dir, img), cls) for img in test])\n","\n","    return train_files, val_files, test_files, classes"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_files, val_files, test_files, classes = split_data(crop_root)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(f\"Train files: {len(train_files)}\")\n","print(f\"Validation files: {len(val_files)}\")\n","print(f\"Test files: {len(test_files)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["inception_size = 299\n","other_size = 224"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_gen_args = dict(rescale=1./255,\n","                     shear_range=0.2,\n","                     zoom_range=0.2,\n","                     horizontal_flip=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_transforms = {\n","    'InceptionV3': ImageDataGenerator(**data_gen_args),\n","    'Others': ImageDataGenerator(**data_gen_args),\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class CustomDataset(Sequence):\n","    def __init__(self, file_paths, class_to_idx, batch_size=32, image_size=(224, 224), shuffle=True):\n","        self.file_paths = file_paths\n","        self.class_to_idx = class_to_idx\n","        self.batch_size = batch_size\n","        self.image_size = image_size\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        return int(np.floor(len(self.file_paths) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        batch_paths = self.file_paths[index * self.batch_size:(index + 1) * self.batch_size]\n","        images = []\n","        labels = []\n","        for img_path, cls in batch_paths:\n","            image = Image.open(img_path).resize(self.image_size)\n","            image = np.array(image) / 255.0\n","            label = self.class_to_idx[cls]\n","            images.append(image)\n","            labels.append(label)\n","        return np.array(images), to_categorical(np.array(labels), num_classes=len(self.class_to_idx))\n","\n","    def on_epoch_end(self):\n","        if self.shuffle:\n","            np.random.shuffle(self.file_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class_to_idx = {cls: idx for idx, cls in enumerate(classes)}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_dataset_inception = CustomDataset(train_files, class_to_idx, image_size=(inception_size, inception_size))\n","val_dataset_inception = CustomDataset(val_files, class_to_idx, image_size=(inception_size, inception_size))\n","test_dataset_inception = CustomDataset(test_files, class_to_idx, image_size=(inception_size, inception_size))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_dataset_others = CustomDataset(train_files, class_to_idx, image_size=(other_size, other_size))\n","val_dataset_others = CustomDataset(val_files, class_to_idx, image_size=(other_size, other_size))\n","test_dataset_others = CustomDataset(test_files, class_to_idx, image_size=(other_size, other_size))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def create_model(base_model, num_classes):\n","    x = base_model.output\n","    x = layers.GlobalAveragePooling2D()(x)\n","    x = layers.Dense(1024, activation='relu')(x)\n","    predictions = layers.Dense(num_classes, activation='softmax')(x)\n","    return models.Model(inputs=base_model.input, outputs=predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_model(model, train_dataset, val_dataset, epochs=40, initial_lr=0.001):\n","    model.compile(optimizer=optimizers.Adam(lr=initial_lr),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    \n","    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","    model.fit(train_dataset, validation_data=val_dataset, epochs=epochs, callbacks=[early_stopping])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def evaluate_model(model, test_dataset):\n","    results = model.evaluate(test_dataset)\n","    test_loss, test_accuracy = results[0], results[1] * 100\n","    return test_loss, test_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["crops = ['Cherry']\n","results = {}\n","\n","for crop in crops:\n","    train_dataset_inception = CustomDataset(train_files, class_to_idx, image_size=(inception_size, inception_size))\n","    val_dataset_inception = CustomDataset(val_files, class_to_idx, image_size=(inception_size, inception_size))\n","    test_dataset_inception = CustomDataset(test_files, class_to_idx, image_size=(inception_size, inception_size))\n","\n","    train_dataset_others = CustomDataset(train_files, class_to_idx, image_size=(other_size, other_size))\n","    val_dataset_others = CustomDataset(val_files, class_to_idx, image_size=(other_size, other_size))\n","    test_dataset_others = CustomDataset(test_files, class_to_idx, image_size=(other_size, other_size))\n","\n","    num_classes = len(class_to_idx)\n","\n","    pretrained_models = {\n","        'InceptionV3': InceptionV3(weights='imagenet', include_top=False, input_shape=(inception_size, inception_size, 3)),\n","        'ResNet152': ResNet152(weights='imagenet', include_top=False, input_shape=(other_size, other_size, 3)),\n","        'VGG19': VGG19(weights='imagenet', include_top=False, input_shape=(other_size, other_size, 3)),\n","    }\n","\n","    crop_results = {}\n","\n","    for model_name, base_model in pretrained_models.items():\n","        model = create_model(base_model, num_classes)\n","        \n","        if model_name == 'InceptionV3':\n","            train_dataset = train_dataset_inception\n","            val_dataset = val_dataset_inception\n","            test_dataset = test_dataset_inception\n","        else:\n","            train_dataset = train_dataset_others\n","            val_dataset = val_dataset_others\n","            test_dataset = test_dataset_others\n","\n","        print(f'--------------- Training model: {model_name}')\n","        train_model(model, train_dataset, val_dataset)\n","\n","        test_loss, test_accuracy = evaluate_model(model, test_dataset)\n","\n","        crop_results[model_name] = {\n","            'model': model,\n","            'test_loss': test_loss,\n","            'test_accuracy': test_accuracy\n","        }\n","        print(f'{crop} - {model_name} Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n","        print(f'\\n')\n","\n","    results[crop] = crop_results"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def display_model_metrics_table(results, test_dataset):\n","    metrics_data = []\n","\n","    for crop, crop_results in results.items():\n","        for model_name, model_info in crop_results.items():\n","            model = model_info['model']\n","            all_labels = []\n","            all_predicted = []\n","\n","            for images, labels in test_dataset:\n","                outputs = model.predict(images)\n","                predicted = np.argmax(outputs, axis=1)\n","                all_labels.extend(np.argmax(labels, axis=1))\n","                all_predicted.extend(predicted)\n","\n","            precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predicted, average='macro')\n","            \n","            metrics_data.append({\n","                'Crop': crop,\n","                'Model': model_name,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1-score': f1\n","            })\n","\n","    metrics_df = pd.DataFrame(metrics_data)\n","    display(metrics_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def display_classification_report(model, test_dataset):\n","    all_labels = []\n","    all_predicted = []\n","\n","    for images, labels in test_dataset:\n","        outputs = model.predict(images)\n","        predicted = np.argmax(outputs, axis=1)\n","        all_labels.extend(np.argmax(labels, axis=1))\n","        all_predicted.extend(predicted)\n","\n","    report = classification_report(all_labels, all_predicted, target_names=[str(i) for i in range(test_dataset.num_classes)])\n","    print(report)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def display_classification_results(model, test_dataset, num_images=5):\n","    images, labels = next(iter(test_dataset))\n","    outputs = model.predict(images[:num_images])\n","    predicted = np.argmax(outputs, axis=1)\n","    \n","    fig, axes = plt.subplots(1, num_images, figsize=(20, 8))\n","    fig.suptitle('Classification Results', fontsize=16)\n","    \n","    for i in range(num_images):\n","        ax = axes[i]\n","        img = images[i]\n","        img = np.clip(img, 0, 1)\n","        ax.imshow(img)\n","        ax.set_title(f'True: {np.argmax(labels[i])}\\n Pred: {predicted[i]}')\n","        ax.axis('off')\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["display_model_metrics_table(results, test_dataset_inception)\n","for crop, crop_results in results.items():\n","    for model_name in crop_results.keys():\n","        print(f'Displaying results for {crop} - {model_name}')\n","        display_classification_results(crop_results[model_name]['model'], test_dataset_inception)\n","        print(f'Displaying classification report for {crop} - {model_name}')\n","        display_classification_report(crop_results[model_name]['model'], test_dataset_inception)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4056201,"sourceId":7048575,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
