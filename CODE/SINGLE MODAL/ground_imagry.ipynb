{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS, GPSTAGS\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets.folder import default_loader, IMG_EXTENSIONS\n",
    "\n",
    "from vit_pytorch import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exif_data(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image.verify()\n",
    "    exif_data = image._getexif()\n",
    "    if not exif_data:\n",
    "        return None\n",
    "\n",
    "    exif = {}\n",
    "    for tag, value in exif_data.items():\n",
    "        decoded = TAGS.get(tag, tag)\n",
    "        exif[decoded] = value\n",
    "\n",
    "    return exif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geotagging(exif):\n",
    "    if not exif:\n",
    "        return None\n",
    "\n",
    "    geotagging = {}\n",
    "    for (key, val) in GPSTAGS.items():\n",
    "        if key in exif:\n",
    "            geotagging[val] = exif[key]\n",
    "\n",
    "    return geotagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(geotags):\n",
    "    def convert_to_degrees(value):\n",
    "        d, m, s = value\n",
    "        return d + (m / 60.0) + (s / 3600.0)\n",
    "\n",
    "    lat = convert_to_degrees(geotags['GPSLatitude'])\n",
    "    if geotags['GPSLatitudeRef'] != 'N':\n",
    "        lat = -lat\n",
    "\n",
    "    lon = convert_to_degrees(geotags['GPSLongitude'])\n",
    "    if geotags['GPSLongitudeRef'] != 'E':\n",
    "        lon = -lon\n",
    "\n",
    "    return (lat, lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def get_exif_data(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        # For TIFF images, use _getexif() for compatibility, but it might not exist.\n",
    "        if hasattr(image, '_getexif'):  # Check if the _getexif attribute exists\n",
    "            exif_data = image._getexif()\n",
    "        else:\n",
    "            # For TIFF and other formats, attempt to access the info dictionary directly\n",
    "            exif_data = image.info\n",
    "    except AttributeError as e:\n",
    "        print(f\"Could not retrieve EXIF data: {e}\")\n",
    "        exif_data = None\n",
    "    return exif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_exif_data(\"/Users/izzymohamed/Downloads/Cherry/03_11_2021/Aerial_UAV_photos/green.rgb.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_in_folder(folder_path):\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('jpg', 'jpeg', 'png', 'tiff')):\n",
    "                image_path = os.path.join(root, file)\n",
    "                exif_data = get_exif_data(image_path)\n",
    "                geotags = get_geotagging(exif_data)\n",
    "                if geotags:\n",
    "                    coordinates = get_coordinates(geotags)\n",
    "                    print(f\"Image: {file} - Coordinates: {coordinates}\")\n",
    "                else:\n",
    "                    print(f\"Image: {file} - No geotagging data found.\")\n",
    "\n",
    "# Example usage\n",
    "folder_path = '/Users/izzymohamed/Downloads/Cherry/03_11_2021'\n",
    "process_images_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define main directories\n",
    "base_dir = '/Users/izzymohamed/Downloads/Cherry v2'\n",
    "\n",
    "# Define crop directories\n",
    "crop_root = base_dir + '/Ground_RGB_Photos'\n",
    "\n",
    "# Define train and test directories\n",
    "train_set_dir = crop_root + '/train_set'\n",
    "test_set_dir = crop_root + '/test_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove .DS_Store files\n",
    "def remove_ds_store(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == '.DS_Store' or '.DS_Store' in file:\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"Removing {file_path}\")\n",
    "                os.remove(file_path)\n",
    "\n",
    "# Remove .DS_Store files from train, validation, and test directories\n",
    "remove_ds_store(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all directories inside the main root\n",
    "def list_directories(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        level = root.replace(path, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "\n",
    "# Call the function with the path you want to explore\n",
    "list_directories(crop_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split training data into training and validation sets\n",
    "def split_train_val(base_train_dir, train_dir, val_dir, val_split=0.2):\n",
    "    classes = os.listdir(base_train_dir)\n",
    "    for cls in classes:\n",
    "        print('     Processing class: {}'.format(cls))\n",
    "        if cls == '.DS_Store':\n",
    "            continue\n",
    "        \n",
    "        class_train_dir = os.path.join(base_train_dir, cls)\n",
    "        os.makedirs(os.path.join(train_dir, cls), exist_ok=True)\n",
    "        os.makedirs(os.path.join(val_dir, cls), exist_ok=True)\n",
    "        \n",
    "        images = os.listdir(class_train_dir)\n",
    "        train, val = train_test_split(images, test_size=val_split)\n",
    "        \n",
    "        for img in train:\n",
    "            shutil.copy(os.path.join(class_train_dir, img), os.path.join(train_dir, cls, img))\n",
    "        for img in val:\n",
    "            shutil.copy(os.path.join(class_train_dir, img), os.path.join(val_dir, cls, img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Check if the output is a tuple (for InceptionV3)\n",
    "            if isinstance(outputs, tuple):\n",
    "                outputs = outputs[0]  # Use only the main output\n",
    "                \n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_model(model, train_loader, val_loader, num_classes, device, epochs=10, fine_tune_epochs=5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Check if the output is a tuple (for InceptionV3)\n",
    "            if isinstance(outputs, tuple):\n",
    "                outputs = outputs[0]  # Use only the main output\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "    # Fine-tune the model\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    for epoch in range(fine_tune_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Check if the output is a tuple (for InceptionV3)\n",
    "            if isinstance(outputs, tuple):\n",
    "                outputs = outputs[0]  # Use only the main output\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Fine-tune Epoch {epoch+1}/{fine_tune_epochs}, Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each crop directory and train models\n",
    "crops = ['Armillaria_Stage_1',\n",
    "'Armillaria_Stage_2',\n",
    "'Armillaria_Stage_3',\n",
    "'Healthy']\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all classes in the training directory\n",
    "def find_classes(dir):\n",
    "    # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "        print(f\"Created directory: {dir}\")\n",
    "    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d)) and not d.startswith('.')]\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx\n",
    "\n",
    "for crop in crops:\n",
    "    train_dir = os.path.join(base_dir, crop, 'train_set')\n",
    "    test_dir = os.path.join(base_dir, crop, 'test_set')\n",
    "    print(find_classes(train_dir))\n",
    "    print(find_classes(test_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations\n",
    "data_transforms1 = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),  # Resize to the required input size\n",
    "        transforms.RandomResizedCrop(299),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),  # Resize to the required input size\n",
    "        transforms.CenterCrop(299),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),  # Resize to the required input size\n",
    "        transforms.CenterCrop(299),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "def is_valid_file(path):\n",
    "    return not path.endswith('.DS_Store') or 'DS_Store' not in path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for crop in crops:\n",
    "    print(f'Processing crop: {crop}')\n",
    "    \n",
    "    crop_train_dir = os.path.join(base_dir, crop, 'train_set')\n",
    "    crop_test_dir = os.path.join(base_dir, crop, 'test_set')\n",
    "    \n",
    "    train_dir = f'temp_{crop}_train'\n",
    "    validation_dir = f'temp_{crop}_val'\n",
    "    \n",
    "    split_train_val(crop_train_dir, train_dir, validation_dir)\n",
    "    \n",
    "    # Ensure the train directory exists\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir, exist_ok=True)\n",
    "        print(f\"Created directory: {train_dir}\")\n",
    "\n",
    "    # Ensure the validation directory exists\n",
    "    if not os.path.exists(validation_dir):\n",
    "        os.makedirs(validation_dir, exist_ok=True)\n",
    "        print(f\"Created directory: {validation_dir}\")\n",
    "\n",
    "    # Ensure the test directory exists\n",
    "    if not os.path.exists(crop_test_dir):\n",
    "        os.makedirs(crop_test_dir, exist_ok=True)\n",
    "        print(f\"Created directory: {crop_test_dir}\")\n",
    "\n",
    "    # Now you can safely create datasets and dataloaders\n",
    "    train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'], is_valid_file=is_valid_file)\n",
    "    val_dataset = datasets.ImageFolder(validation_dir, transform=data_transforms['val'], is_valid_file=is_valid_file)\n",
    "    test_dataset = datasets.ImageFolder(crop_test_dir, transform=data_transforms['test'], is_valid_file=is_valid_file)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    num_classes = len(train_dataset.classes)\n",
    "    \n",
    "    # Ensure test dataset classes match train dataset classes\n",
    "    test_dataset.class_to_idx = train_dataset.class_to_idx\n",
    "    \n",
    "    # Models to compare\n",
    "    pretrained_models = {\n",
    "        'EfficientNetB0': EfficientNet.from_pretrained('efficientnet-b0'),\n",
    "        'InceptionV3': models.inception_v3(pretrained=True),\n",
    "        'ResNet50': models.resnet50(pretrained=True),\n",
    "        'ViT': ViT(\n",
    "            image_size = 224,\n",
    "            patch_size = 16,\n",
    "            num_classes = num_classes,\n",
    "            dim = 1024,\n",
    "            depth = 6,\n",
    "            heads = 16,\n",
    "            mlp_dim = 2048,\n",
    "            dropout = 0.1,\n",
    "            emb_dropout = 0.1\n",
    "        ),\n",
    "        # 'AttentionAugmentedResNet50': models.resnet50(pretrained=True)  # Placeholder, implement AttentionAugmentedResNet50\n",
    "    }\n",
    "\n",
    "    crop_results = {}\n",
    "\n",
    "    for model_name, base_model in pretrained_models.items():\n",
    "        if model_name == 'InceptionV3':\n",
    "            base_model.AuxLogits.fc = nn.Linear(base_model.AuxLogits.fc.in_features, num_classes)\n",
    "            base_model.fc = nn.Linear(base_model.fc.in_features, num_classes)\n",
    "        elif model_name == 'EfficientNetB0':\n",
    "            base_model._fc = nn.Linear(base_model._fc.in_features, num_classes)\n",
    "        elif model_name == 'ViT':\n",
    "            base_model.mlp_head = nn.Linear(base_model.mlp_head.in_features, num_classes)\n",
    "        elif model_name == 'AttentionAugmentedResNet50':\n",
    "            # Implement AttentionAugmentedResNet50 here\n",
    "            pass\n",
    "        else:\n",
    "            base_model.fc = nn.Linear(base_model.fc.in_features, num_classes)\n",
    "        \n",
    "        print(f'--------------- Training model: {model_name} for crop: {crop} ---------------')\n",
    "        model = create_and_train_model(base_model, train_loader, val_loader, num_classes, device)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        test_loss, test_accuracy = evaluate_model(model, test_loader, nn.CrossEntropyLoss(), device)\n",
    "        \n",
    "        crop_results[model_name] = {\n",
    "            'model': model,\n",
    "            'test_loss': test_loss,\n",
    "            'test_accuracy': test_accuracy\n",
    "        }\n",
    "        print(f'{crop} - {model_name} Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "    results[crop] = crop_results\n",
    "\n",
    "    # Clean up temporary directories\n",
    "    shutil.rmtree(train_dir)\n",
    "    shutil.rmtree(validation_dir)\n",
    "\n",
    "print('All crops processed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison of accuracy for each model for each crop\n",
    "for crop, crop_results in results.items():\n",
    "    accuracies = [result['accuracy'] for result in crop_results.values()]\n",
    "    model_names = list(crop_results.keys())\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(model_names, accuracies)\n",
    "    plt.title(f'Model test accuracy comparison for {crop}')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.xlabel('Model')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some correctly and incorrectly classified images\n",
    "def display_classification_results(model, test_loader, num_images=5):\n",
    "    model.eval()\n",
    "    class_labels = test_loader.dataset.classes\n",
    "    images, labels = next(iter(test_loader))\n",
    "    images, labels = images[:num_images], labels[:num_images]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(20, 8))\n",
    "    fig.suptitle('Classification Results', fontsize=16)\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        ax = axes[i]\n",
    "        img = images[i].cpu().numpy().transpose((1, 2, 0))\n",
    "        img = np.clip(img, 0, 1)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f'True: {class_labels[labels[i]]}, Pred: {class_labels[predicted[i]]}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results for MobileNetV2 for each crop\n",
    "for crop, crop_results in results.items():\n",
    "    print(f'Displaying results for {crop} - MobileNetV2')\n",
    "    display_classification_results(crop_results['MobileNetV2']['model'], test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
